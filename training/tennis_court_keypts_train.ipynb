{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import json\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, Linear\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training data to images and keypts (arr) so it can go through resnet.\n",
    "\n",
    "class KeyPtsDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dire = img_dir\n",
    "        with open(data_file) as f:\n",
    "            self.data = json.load(f)\n",
    "        self.transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def __len__(self): return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = cv2.imread(f\"{self.img_dire}/{item['id']}.png\")\n",
    "        h, w = img.shape[:2]\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transforms(img)\n",
    "        kps = np.array(item['kps']).flatten().astype(np.float32)\n",
    "        kps[::2] = 224.0 / w # adjust x\n",
    "        kps[1::2] = 224.0/h # adjust y\n",
    "        return img, kps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = KeyPtsDataset('data/images', 'data/data_train.json'), KeyPtsDataset('data/images', 'data/data_val.json')\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = Linear(model.fc.in_features, 14 * 2) # replace last layer: fine tuning (custom output size 14 keypts * 2 (ht and width))\n",
    "loss_fn = MSELoss()\n",
    "optim = Adam(model.parameters(), lr=1e-4)\n",
    "# Training\n",
    "epochs=20\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(train_loader, unit='batch', desc=f\"Epoch {epoch+1}/{epochs}\") as t_epoch:\n",
    "        for i, (img, kps) in enumerate(t_epoch):\n",
    "            img, kps = img.to(device), kps.to(device)\n",
    "            optim.zero_grad()\n",
    "            outputs = model(img)\n",
    "            loss = loss_fn(outputs, kps)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            t_epoch.set_postfix(loss=loss.item())\n",
    "\n",
    "torch.save(model.state_dict(), \"keypointsModel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom?\n",
    "# \n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self, num_keypoints=14):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Custom block definition\n",
    "        def conv_block(in_channels, out_channels, stride=1):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "        # Initial layers\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Stages\n",
    "        self.stage1 = self._make_stage(64, 64, 3)\n",
    "        self.stage2 = self._make_stage(256, 128, 4, stride=2)\n",
    "        self.stage3 = self._make_stage(512, 256, 6, stride=2)\n",
    "        self.stage4 = self._make_stage(1024, 512, 3, stride=2)\n",
    "        \n",
    "        # Global average pooling and final layer\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, num_keypoints * 2)\n",
    "    \n",
    "    def _make_stage(self, in_channels, out_channels, num_blocks, stride=1):\n",
    "        layers = []\n",
    "        # First block might change stride and channel depth\n",
    "        layers.append(nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        ))\n",
    "        \n",
    "        # Subsequent blocks\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(nn.Sequential(\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
